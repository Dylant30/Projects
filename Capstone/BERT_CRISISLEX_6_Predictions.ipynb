{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT CRISISLEX 6 Predictions",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgagPvoDlAtI",
        "colab_type": "text"
      },
      "source": [
        "# Preparation of Notebook and Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISlaqyWRkJso",
        "colab_type": "code",
        "outputId": "e25f9e81-9272-4dc1-9935-6cbc6151678d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6TjJz9hh5iE",
        "colab_type": "code",
        "outputId": "8a60177d-8cb2-4db7-ac29-dd87df23c86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tweet-preprocessor\n",
        "import transformers\n",
        "from transformers import *\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import preprocessor as p\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import io\n",
        "\n",
        "%matplotlib inline  \n",
        "print('Transformers version: ', transformers.__version__)\n",
        "print('Tensorflow version: ', tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 60.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 37.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 57.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=21b6a47ad3544d91869eb42be67869de2ce8bd33bdd192efa7cf8bd4e60ba1ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n",
            "Collecting tweet-preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/2a/f8/810ec35c31cca89bc4f1a02c14b042b9ec6c19dd21f7ef1876874ef069a6/tweet-preprocessor-0.5.0.tar.gz\n",
            "Building wheels for collected packages: tweet-preprocessor\n",
            "  Building wheel for tweet-preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tweet-preprocessor: filename=tweet_preprocessor-0.5.0-cp36-none-any.whl size=7947 sha256=d40ad46b71ca1afeb00d4cc01e09149b656a0f27ed224c6f6a71ee30145d5133\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/27/cc/49938e98a2470802ebdefae9d2b3f524768e970c1ebbe2dc4a\n",
            "Successfully built tweet-preprocessor\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.5.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Transformers version:  2.5.1\n",
            "Tensorflow version:  1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmLanbUtjQxM",
        "colab_type": "code",
        "outputId": "93fb4a71-a070-42e6-f3e3-86277304778b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():     \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsC8xNnglHJY",
        "colab_type": "text"
      },
      "source": [
        "# Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZodCqQijg1m",
        "colab_type": "code",
        "outputId": "9af2654c-0f9e-41a5-b9ba-4131ffba801e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#importing all datasets\n",
        "sandy_df = pd.read_csv('./drive/My Drive/GA/capstone/data/2012_Sandy_Hurricane-ontopic_offtopic.csv')\n",
        "alberta_df = pd.read_csv('./drive/My Drive/GA/capstone/data/2013_Alberta_Floods-ontopic_offtopic.csv')\n",
        "boston_df = pd.read_csv('./drive/My Drive/GA/capstone/data/2013_Boston_Bombings-ontopic_offtopic.csv')\n",
        "oklahoma_df = pd.read_csv('./drive/My Drive/GA/capstone/data/2013_Oklahoma_Tornado-ontopic_offtopic.csv')\n",
        "queensland_df = pd.read_csv('./drive/My Drive/GA/capstone/data/2013_Queensland_Floods-ontopic_offtopic.csv')\n",
        "west_texas_df = pd.read_csv('./drive/My Drive/GA/capstone/data/2013_West_Texas_Explosion-ontopic_offtopic.csv')\n",
        "super_df = pd.concat([sandy_df,alberta_df,boston_df,oklahoma_df,queensland_df,west_texas_df])\n",
        "super_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60082, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5bis1d4lJTA",
        "colab_type": "text"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn7IPWvdrTI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import regex as re\n",
        "def tidy_up(dataframe): #renaming columns to remove the 'space' and to change the label to binary.\n",
        "  dataframe.rename(columns={\" tweet\":\"tweet\",\" label\":\"label\"},inplace=True)\n",
        "  dataframe.label = dataframe.label.map({'off-topic':0,'on-topic':1})\n",
        "  dataframe.drop(columns=['tweet id'],inplace=True)\n",
        "  dataframe.drop_duplicates(subset='tweet',keep='last',inplace=True)\n",
        "  p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED)\n",
        "  dataframe['tweet']=[p.clean(x) for x in dataframe['tweet']]\n",
        "  dataframe['tweet']=[re.sub(r'(&amp;)|(&lt;)|(b&gt;)|([!?.]*[!?.])',\"\",x) for x in dataframe['tweet']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_Yv9WY3TCDN",
        "colab_type": "code",
        "outputId": "207f988b-096e-4c76-e01e-cb7e112fd982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "tidy_up(super_df)\n",
        "super_df['bert_predict'] = 0\n",
        "super_df.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>bert_predict</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9266</th>\n",
              "      <td>: The #Siksika First Nation near Calgary has a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3453</th>\n",
              "      <td>will never notice me and it kills me</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9833</th>\n",
              "      <td>#yycflood This page is for anyone in Calgary s...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4993</th>\n",
              "      <td>excuse me You're the one who showed them your ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3153</th>\n",
              "      <td>Having the option to sleep all day is amazing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  tweet  label  bert_predict\n",
              "9266  : The #Siksika First Nation near Calgary has a...      1             0\n",
              "3453               will never notice me and it kills me      0             0\n",
              "9833  #yycflood This page is for anyone in Calgary s...      1             0\n",
              "4993  excuse me You're the one who showed them your ...      0             0\n",
              "3153      Having the option to sleep all day is amazing      0             0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1ue5KAisjkX",
        "colab_type": "code",
        "outputId": "a52e91c6-e06a-4e73-ddd8-5b6ea58a83db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "super_df.label.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    27879\n",
              "0    27498\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXTrG0HylNwT",
        "colab_type": "text"
      },
      "source": [
        "# Loading fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGgiCKSIDPMF",
        "colab_type": "code",
        "outputId": "9dc2ffe6-02a2-42fd-b9da-ec4abda56ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "output_dir = './drive/My Drive/GA/capstone/BERT with cleaned tweets' #loading cleaned tweets BERT\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME4JElzslRn9",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFuS0XPqHj2j",
        "colab_type": "code",
        "outputId": "69cac85b-ca55-4239-9471-f5c1802a8043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "super_df['bert_predict_clean'] = 0\n",
        "\n",
        "# Create sentence and label lists\n",
        "tweets = super_df.tweet.values\n",
        "labels = super_df.bert_predict_clean.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for tweet in tweets:\n",
        "    encoded_tweet = tokenizer.encode( tweet, add_special_tokens = True )\n",
        "    input_ids.append(encoded_tweet)\n",
        "\n",
        "# Pad our input tokens\n",
        "MAX_LEN = max([len(i) for i in input_ids])\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "# Predictions\n",
        "\n",
        "print('Predicting labels for {:,} tweets...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions_clean , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions_clean.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 55,377 tweets...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2aWp6AbHoSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_flat_prediction = [item for sublist in predictions_clean for item in sublist]\n",
        "clean_flat_predictions = np.argmax(clean_flat_prediction, axis=1).flatten()\n",
        "super_df['bert_predict_clean'] = clean_flat_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuGE6lm6H7W2",
        "colab_type": "code",
        "outputId": "36cd44b6-3819-4c0d-ddd5-14940c2e0890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "tn, fp, fn, tp = confusion_matrix(super_df['label'], super_df['bert_predict_clean']).ravel()\n",
        "print(\"True Negatives: %s\" % tn)\n",
        "print(\"False Positives: %s\" % fp)\n",
        "print(\"False Negatives: %s\" % fn)\n",
        "print(\"True Positives: %s\" % tp)\n",
        "\n",
        "accuracy_clean = (tp + tn) / (tp + tn + fp + fn)\n",
        "print(f'Accuracy: {round(accuracy_clean,4)}')\n",
        "\n",
        "misclass_clean = (fp + fn) / (tp + tn + fp + fn)\n",
        "print(f'Misclassification Rate: {round(misclass_clean,4)}')\n",
        "\n",
        "spec_clean = tn / (tn + fp) #how many of the 'spam' was correctly classified\n",
        "print(f'Specificity: {round(spec_clean,4)}')\n",
        "\n",
        "sens_clean = tp / (tp + fn) #how many of the disasters was correctly identified\n",
        "print(f'Sensitivity: {round(sens_clean,4)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Negatives: 25785\n",
            "False Positives: 1713\n",
            "False Negatives: 6346\n",
            "True Positives: 21533\n",
            "Accuracy: 0.8545\n",
            "Misclassification Rate: 0.1455\n",
            "Specificity: 0.9377\n",
            "Sensitivity: 0.7724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRnImD3AInWw",
        "colab_type": "code",
        "outputId": "1066c4d1-ce0e-4fb4-fd7a-9f73e5612fb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "super_df.loc[super_df['bert_predict']!=super_df['label']]['tweet'].sample().to_string()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"7047    Hurricane sandy is on it's way\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm1mvQtLLCfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "super_df.to_csv('./drive/My Drive/GA/capstone/super_df.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1M5Pbo-QeSl",
        "colab_type": "code",
        "outputId": "3f612df2-2f6c-4cf0-fcc0-3698068b6f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "super_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>bert_predict</th>\n",
              "      <th>bert_predict_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I've got enough candles to supply a Mexican family</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sandy be soooo mad that she be shattering our doors and shiet #HurricaneSandy</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                           tweet  ...  bert_predict_clean\n",
              "0  I've got enough candles to supply a Mexican family                             ...  0                 \n",
              "1  Sandy be soooo mad that she be shattering our doors and shiet #HurricaneSandy  ...  0                 \n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI0FFz2-_ujy",
        "colab_type": "text"
      },
      "source": [
        "BERT struggled when the texts are not referring directly to the disaster that is occuring. It also seems to miss the tweets with a more positive sentiment in the message."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0KV2QBSk6vD",
        "colab_type": "text"
      },
      "source": [
        "BERT is able to identify some of the mislabelled tweets correctly as disaster related. It seems to be able to pick up tweets describing adverse weather and may classify them as disaster-related."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilLMQoF4A0SK",
        "colab_type": "text"
      },
      "source": [
        "# Visualisations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eux8DbHcx--",
        "colab_type": "text"
      },
      "source": [
        "Visualisation of predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Ydmbblnk0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tweet_length_graph(df,col,label,color,kde):\n",
        "    tweet_length = []\n",
        "    for x in df[col]:\n",
        "        tweet_length.append(len(x.split()))\n",
        "    sns.distplot(tweet_length,kde=kde,bins=np.arange(min(tweet_length), max(tweet_length) + 1),label=label,color=color)\n",
        "    plt.title('Words in Tweets')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xlabel('Tweet Length')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmuYEZoAT-D6",
        "colab_type": "code",
        "outputId": "9e825eee-211b-4714-ba46-f6afcf5413c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "bert_yes = super_df.loc[(super_df['bert_predict_clean']==1) & (super_df['label']==0)]\n",
        "bert_no = super_df.loc[(super_df['bert_predict_clean']==0) & (super_df['label']==1)]\n",
        "print(bert_yes.shape)\n",
        "print(bert_no.shape)\n",
        "plt.figure(figsize=(10,5))\n",
        "tweet_length_graph(bert_no,'tweet','ACTUAL','mediumblue',True)\n",
        "tweet_length_graph(bert_yes,'tweet','BERT','orangered',True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1713, 4)\n",
            "(6346, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFNCAYAAABFbcjcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fKULLHsUdbb",
        "colab_type": "code",
        "outputId": "6c0efd17-5209-4e92-df0c-e13e46662987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "super_df.loc[super_df['bert_predict_clean']!=super_df['label']][['tweet','label','bert_predict_clean']].sample(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "      <th>bert_predict_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9026</th>\n",
              "      <td>Scratch that Two buses now #abflood</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6539</th>\n",
              "      <td>: Everyone send well wishes to keep her mind away from the things happening in her home town, Oklahoma Stay…</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9421</th>\n",
              "      <td>: This mothafucka just tweeted On my way back MDDa Fuck BACK Nigga we bout to have a hurricaneyou better</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9168</th>\n",
              "      <td>Tornado Alley To Spark Up After Mid-May —</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6086</th>\n",
              "      <td>: Patriots owner Robert Kraft will match donations, up to $100,000, made to this website for Boston Marathon relief htt</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2612</th>\n",
              "      <td>So a big storm is about to smack Brisbane Fak u gooby Had enough last weekend</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2829</th>\n",
              "      <td>We live right by there Want to help Pls tweet if u find info on how to help</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>Lost power when I was about to taste my first bite out of my sandwich Lmao thank God it's back</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5150</th>\n",
              "      <td>: Here's a view of the sea of volunteers at McMahon So proud of my city #yycflood #yychelps</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6522</th>\n",
              "      <td>“: what if gangnam style was really a giant raindance and we brought this hurricane on ourselves”</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                         tweet  ...  bert_predict_clean\n",
              "9026  Scratch that Two buses now #abflood                                                                                       ...  0                 \n",
              "6539  : Everyone send well wishes to keep her mind away from the things happening in her home town, Oklahoma Stay…              ...  0                 \n",
              "9421  : This mothafucka just tweeted On my way back MDDa Fuck BACK Nigga we bout to have a hurricaneyou better                  ...  0                 \n",
              "9168  Tornado Alley To Spark Up After Mid-May —                                                                                 ...  1                 \n",
              "6086  : Patriots owner Robert Kraft will match donations, up to $100,000, made to this website for Boston Marathon relief htt   ...  0                 \n",
              "2612  So a big storm is about to smack Brisbane Fak u gooby Had enough last weekend                                             ...  1                 \n",
              "2829  We live right by there Want to help Pls tweet if u find info on how to help                                               ...  0                 \n",
              "773   Lost power when I was about to taste my first bite out of my sandwich Lmao thank God it's back                            ...  0                 \n",
              "5150  : Here's a view of the sea of volunteers at McMahon So proud of my city #yycflood #yychelps                               ...  0                 \n",
              "6522  “: what if gangnam style was really a giant raindance and we brought this hurricane on ourselves”                         ...  0                 \n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k_0vMKrY_nI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}