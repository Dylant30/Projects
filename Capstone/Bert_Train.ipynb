{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Train",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8164d5da56d4c0eac0e22e5a9e27dc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4ce87b1e5aeb432d9dce778d79af3dc9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6d90a90681874f7fbd0d89079a00b456",
              "IPY_MODEL_c659b2d477414e708e9c4ce8b7659c19"
            ]
          }
        },
        "4ce87b1e5aeb432d9dce778d79af3dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d90a90681874f7fbd0d89079a00b456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c5c15d84167e44edac776727fc914e0d",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_806009ea40284ea4950c4a73b4f88461"
          }
        },
        "c659b2d477414e708e9c4ce8b7659c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d826b0ec0586464ca9aab211c8710543",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 2.70kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87a61210874446469d89455cb3011dde"
          }
        },
        "c5c15d84167e44edac776727fc914e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "806009ea40284ea4950c4a73b4f88461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d826b0ec0586464ca9aab211c8710543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87a61210874446469d89455cb3011dde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b03aef13321b433eac4d34f41cc73bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea19646bdcd840d49b34b06be0dba877",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ca9b164576e24d878416b7bdd67503cc",
              "IPY_MODEL_d375287d4a1e45cca2252b125ded6595"
            ]
          }
        },
        "ea19646bdcd840d49b34b06be0dba877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca9b164576e24d878416b7bdd67503cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a54bdf0edd34867b7b2332cb53d8a1a",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb59d58f1cfc4bcc84143fa659ccf021"
          }
        },
        "d375287d4a1e45cca2252b125ded6595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_39c4ec0bcb124fc797e518972bc48575",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:17&lt;00:00, 25.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8dd1b5d02b84a328a76f4a0e4b53ec7"
          }
        },
        "8a54bdf0edd34867b7b2332cb53d8a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb59d58f1cfc4bcc84143fa659ccf021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "39c4ec0bcb124fc797e518972bc48575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8dd1b5d02b84a328a76f4a0e4b53ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6YLDEeiid1E",
        "colab_type": "text"
      },
      "source": [
        "# Preparation of Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C29OHTZjUK9F",
        "colab_type": "code",
        "outputId": "7a1f7f58-0fae-44d0-e4bd-916f2d218f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tweet-preprocessor\n",
        "import transformers\n",
        "from transformers import *\n",
        "\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import preprocessor as p\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import io\n",
        "\n",
        "print('Transformers version: ', transformers.__version__)\n",
        "print('Tensorflow version: ', tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.5.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Transformers version:  2.5.1\n",
            "Tensorflow version:  1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_iHsPAzM0tk",
        "colab_type": "code",
        "outputId": "27198072-7737-46c0-9519-3b4b741cf3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLnm1qZSiuc8",
        "colab_type": "text"
      },
      "source": [
        "# Importing Data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32iUlPC9pxJa",
        "colab_type": "code",
        "outputId": "df1c64b2-d66a-4770-fbd5-bc7cda7a92a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_df = pd.read_csv('./drive/My Drive/GA/capstone/data/train.csv')\n",
        "test_df = pd.read_csv('./drive/My Drive/GA/capstone/data/test.csv')\n",
        "submissions = pd.read_csv('./drive/My Drive/GA/capstone/data/sample_submission.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXLeS4FBi0ZQ",
        "colab_type": "text"
      },
      "source": [
        "# Data Cleaning and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1fwazQ23e4H",
        "colab_type": "code",
        "outputId": "0fd238bb-9ee7-4ed6-f7cc-ce86d0a140ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#dropping of duplicate tweets\n",
        "train_df.drop_duplicates(subset='text',keep='last',inplace=True)\n",
        "train_df.reset_index(drop=True,inplace=True)\n",
        "train_df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7503, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Khv4aJjnjNL",
        "colab_type": "code",
        "outputId": "a5a1ba60-7627-4015-a542-876d474f3aaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(train_df.shape[0]))\n",
        "\n",
        "# Display 5 random rows from the data.\n",
        "train_df.sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 7,503\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5233</th>\n",
              "      <td>7598</td>\n",
              "      <td>pandemonium</td>\n",
              "      <td>Nigeria</td>\n",
              "      <td>Pandemonium In Aba As Woman Delivers Baby With...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5707</th>\n",
              "      <td>8280</td>\n",
              "      <td>rioting</td>\n",
              "      <td>heart of darkness, unholy ?</td>\n",
              "      <td>@Georgous__ what alternatives? Legal alternati...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5888</th>\n",
              "      <td>8542</td>\n",
              "      <td>screams</td>\n",
              "      <td>lesa * she/her</td>\n",
              "      <td>@TromboneTristan OOOOOHSHIT OOOHSHIT SCREAMS h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2653</th>\n",
              "      <td>3853</td>\n",
              "      <td>detonation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ignition Knock (Detonation) Sensor-Senso Stand...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>1290</td>\n",
              "      <td>bloody</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>I can't bloody wait!! Sony Sets a Date For Ste...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "5233  7598  ...      1\n",
              "5707  8280  ...      0\n",
              "5888  8542  ...      0\n",
              "2653  3853  ...      1\n",
              "885   1290  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZotEQwHyEOs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cleaning the tweets of links and twitter handles\n",
        "import regex as re\n",
        "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED)\n",
        "train_df['text']=[p.clean(x) for x in train_df['text']]\n",
        "train_df['text']=[re.sub(r'(&amp;)|(&lt;)|(b&gt;)|([!?.]*[!?.])',\"\",x) for x in train_df['text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utG1dWQ8EOnQ",
        "colab_type": "code",
        "outputId": "5c70a6d2-aace-4b31-fac2-9172e8272ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "#plotting the distribution of tweet lengths\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "tweet_length = []\n",
        "for x in train_df['text']:\n",
        "    tweet_length.append(len(x.split()))\n",
        "sns.distplot(tweet_length,kde=False,bins=np.arange(min(tweet_length), max(tweet_length) + 1))\n",
        "plt.title('Words in Tweets')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Tweet Length')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Tweet Length')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFa8LwU2jSBA",
        "colab_type": "text"
      },
      "source": [
        "# BERT Tokenization and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9D-bLBxnuRd",
        "colab_type": "code",
        "outputId": "c3414115-e3d7-4ce2-a873-d90030183c1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "n=55\n",
        "# Print the original sentence.\n",
        "print(' Original: ', train_df['text'][n])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(train_df['text'][n]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(train_df['text'][n])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            " Original:  TRUCK ABLAZE : R21 VOORTREKKER AVE OUTSIDE OR TAMBO INTL CARGO SECTION\n",
            "Tokenized:  ['truck', 'ab', '##laze', ':', 'r', '##21', 'vo', '##ort', '##rek', '##ker', 'ave', 'outside', 'or', 'tam', '##bo', 'int', '##l', 'cargo', 'section']\n",
            "Token IDs:  [4744, 11113, 24472, 1024, 1054, 17465, 29536, 11589, 16816, 5484, 13642, 2648, 2030, 17214, 5092, 20014, 2140, 6636, 2930]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTCMyt4mc6cJ",
        "colab_type": "code",
        "outputId": "3484d9e6-5077-419a-f727-dd4f99bf3022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_df.text = [tokenizer.tokenize(x) for x in train_df.text]\n",
        "train_df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7503, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV268RqWeGyk",
        "colab_type": "code",
        "outputId": "0d3a788c-29c7-4801-c81a-5ccff49e861f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "train_df['length'] = [len(x) for x in train_df.text]\n",
        "train_df = train_df[train_df['length']<=50] #to drop the three unrelated tweets, possibly from weather stations.\n",
        "train_df.reset_index(drop=True,inplace=True)\n",
        "train_df.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7500, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjbAwmUnVHyW",
        "colab_type": "code",
        "outputId": "aa9d41ec-3983-4dc0-8858-2656d63c5d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "train_df.head(2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[our, deeds, are, the, reason, of, this, #, earthquake, may, allah, forgive, us, all]</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[forest, fire, near, la, ron, ##ge, sas, ##k, canada]</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ... target length\n",
              "0  1   NaN     ...  1      14   \n",
              "1  4   NaN     ...  1      9    \n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N072kdk3ryU7",
        "colab_type": "code",
        "outputId": "ca36d2f3-a1fa-4a35-f260-73e4b0ae6201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for word in train_df['text']:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_word = tokenizer.encode(\n",
        "                        word,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_word)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', train_df['text'][117])\n",
        "print('Token IDs:', input_ids[117])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  ['#', 'wisdom', '##wed', 'bonus', '-', '5', 'minute', 'daily', 'habits', 'that', 'could', 'really', 'improve', 'your', 'life', 'how', 'many', 'do', 'you', 'already', 'do', '#', 'life', '##ha', '##cks']\n",
            "Token IDs: [101, 1001, 9866, 15557, 6781, 1011, 1019, 3371, 3679, 14243, 2008, 2071, 2428, 5335, 2115, 2166, 2129, 2116, 2079, 2017, 2525, 2079, 1001, 2166, 3270, 10603, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKcWFF__a7Gd",
        "colab_type": "code",
        "outputId": "62f07503-2028-4f96-d63b-1c8d09921c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "#plotting the distribution of token lengths\n",
        "token_lengths=[len(i) for i in input_ids]\n",
        "sns.distplot(token_lengths,kde=False,bins=np.arange(min(token_lengths), max(token_lengths) + 1))\n",
        "plt.title('Tokens in Tweets')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Number of Tokens')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Number of Tokens')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERG1JIWIiKj9f6mnr088ElDhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-gIYPW7ntLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting the data into X & y\n",
        "tweet = train_df.text.values\n",
        "labels = train_df.target.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8d94ajRsX--",
        "colab_type": "code",
        "outputId": "9df38a3e-6da8-4099-dac1-b076a9de5301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(i) for i in input_ids]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG1bK0IGs00Q",
        "colab_type": "code",
        "outputId": "1b5938da-381c-4cb3-8506-81891ad038da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "MAX_LEN = 50\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 50 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djy4-P_DtA6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for i in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in i]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIdwSnQjtHgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04Mj1uT8twsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUXeXPqrt3Ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crcb09-rj3GK",
        "colab_type": "text"
      },
      "source": [
        "# Loading BERT model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKV3Ii-Bt517",
        "colab_type": "code",
        "outputId": "a1c6d759-c7c2-46a3-8af6-1688ba455327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e8164d5da56d4c0eac0e22e5a9e27dc2",
            "4ce87b1e5aeb432d9dce778d79af3dc9",
            "6d90a90681874f7fbd0d89079a00b456",
            "c659b2d477414e708e9c4ce8b7659c19",
            "c5c15d84167e44edac776727fc914e0d",
            "806009ea40284ea4950c4a73b4f88461",
            "d826b0ec0586464ca9aab211c8710543",
            "87a61210874446469d89455cb3011dde",
            "b03aef13321b433eac4d34f41cc73bc9",
            "ea19646bdcd840d49b34b06be0dba877",
            "ca9b164576e24d878416b7bdd67503cc",
            "d375287d4a1e45cca2252b125ded6595",
            "8a54bdf0edd34867b7b2332cb53d8a1a",
            "eb59d58f1cfc4bcc84143fa659ccf021",
            "39c4ec0bcb124fc797e518972bc48575",
            "e8dd1b5d02b84a328a76f4a0e4b53ec7"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification, can be increased for multi-class tasks\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8164d5da56d4c0eac0e22e5a9e27dc2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b03aef13321b433eac4d34f41cc73bc9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_UFzXJIt7y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8 \n",
        "                )\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs \n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsG__bGjuAeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "    \n",
        "def conf_matrix(pred,labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return confusion_matrix(labels_flat,pred_flat)\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gsZUK2jkUFU",
        "colab_type": "text"
      },
      "source": [
        "# Fine-Tuning BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExlGbaSpuOt2",
        "colab_type": "code",
        "outputId": "6ab92866-5563-42b2-c00d-6a3c617158ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "  \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode.\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    211.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    211.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    211.    Elapsed: 0:00:41.\n",
            "  Batch   160  of    211.    Elapsed: 0:00:55.\n",
            "  Batch   200  of    211.    Elapsed: 0:01:09.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epoch took: 0:01:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.83\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    211.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    211.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    211.    Elapsed: 0:00:42.\n",
            "  Batch   160  of    211.    Elapsed: 0:00:56.\n",
            "  Batch   200  of    211.    Elapsed: 0:01:10.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epoch took: 0:01:14\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    211.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    211.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    211.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    211.    Elapsed: 0:00:57.\n",
            "  Batch   200  of    211.    Elapsed: 0:01:11.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epoch took: 0:01:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    211.    Elapsed: 0:00:14.\n",
            "  Batch    80  of    211.    Elapsed: 0:00:28.\n",
            "  Batch   120  of    211.    Elapsed: 0:00:43.\n",
            "  Batch   160  of    211.    Elapsed: 0:00:57.\n",
            "  Batch   200  of    211.    Elapsed: 0:01:11.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epoch took: 0:01:15\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "becbkkydwz0m",
        "colab_type": "code",
        "outputId": "59ca711f-61f6-45a8-df1a-26ad1e93aedd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()\n",
        "plt.savefig('./drive/My Drive/GA/capstone/bert_output/epoch_loss.png')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAA4EZI4AEAAAA38v8BVirQLFQLsicAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-bxPOkrkZdQ",
        "colab_type": "text"
      },
      "source": [
        "# Predicting on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfyRpTzLzWXj",
        "colab_type": "code",
        "outputId": "6369dc78-aab6-4b3d-dfd4-b20b4649003c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#formatting test data\n",
        "test_df['text']=[p.clean(x) for x in test_df['text']]\n",
        "test_df['text']=[re.sub(r'(&amp;)|(&lt;)|(b&gt;)|([!?.]*[!?.])',\"\",x) for x in test_df['text']]\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(test_df.shape[0]))\n",
        "\n",
        "# Create sentence \n",
        "test_tweet = test_df.text.values\n",
        "labels = submissions.target.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for i in test_tweet:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        i,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 3,263\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3ijjbLvz09l",
        "colab_type": "code",
        "outputId": "10262a8e-cd95-4212-fac9-8c5982f91847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 3,263 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEnkZiw2ZX05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "submissions.target = flat_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHZ0QS9gagXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submissions.to_csv('submission.csv', index = False)\n",
        "!cp submission.csv \"./drive/My Drive/GA/capstone\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50gBrKYa30Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['target'] = flat_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2AmXjVdkiAu",
        "colab_type": "text"
      },
      "source": [
        "# Exporting the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuVxucgJ0IqH",
        "colab_type": "code",
        "outputId": "0e0eb82d-91c1-45f1-d017-bdf97cdd15b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './drive/My Drive/GA/capstone/BERT with cleaned tweets'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./drive/My Drive/GA/capstone/BERT with cleaned tweets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./drive/My Drive/GA/capstone/BERT with cleaned tweets/vocab.txt',\n",
              " './drive/My Drive/GA/capstone/BERT with cleaned tweets/special_tokens_map.json',\n",
              " './drive/My Drive/GA/capstone/BERT with cleaned tweets/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-AlurQ-0JQj",
        "colab_type": "code",
        "outputId": "38cd2272-f30a-4f74-f506-0534c3a64f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!ls -l --block-size=K './drive/My Drive/GA/capstone/BERT with cleaned tweets'"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427948K\n",
            "-rw------- 1 root root      2K Mar 12 07:28 config.json\n",
            "-rw------- 1 root root 427719K Mar 12 07:28 pytorch_model.bin\n",
            "-rw------- 1 root root      1K Mar 12 07:28 special_tokens_map.json\n",
            "-rw------- 1 root root      1K Mar 12 07:28 tokenizer_config.json\n",
            "-rw------- 1 root root    227K Mar 12 07:28 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vu6YGd3Fi-l",
        "colab_type": "code",
        "outputId": "af75b869-5792-4526-ea06-d5cb643ec41f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on training set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(train_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "train_predictions , train_true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in train_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  train_predictions.append(logits)\n",
        "  train_true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 6,750 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkuQMsn0gEGn",
        "colab_type": "code",
        "outputId": "030a7f0e-e3e4-42bb-bc0a-c6b0720aa845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on train-validation set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(validation_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "val_predictions , val_true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in validation_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  val_predictions.append(logits)\n",
        "  val_true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 750 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JViZLRhqHfhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_flat_predictions = [item for sublist in train_predictions for item in sublist]\n",
        "train_flat_predictions = np.argmax(train_flat_predictions, axis=1).flatten()\n",
        "\n",
        "val_flat_predictions = [item for sublist in val_predictions for item in sublist]\n",
        "val_flat_predictions = np.argmax(val_flat_predictions, axis=1).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3zHp8vdI0Ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conf_unravel(true,pred):\n",
        "  tn, fp, fn, tp = confusion_matrix(true, pred).ravel()\n",
        "  print(\"True Negatives: %s\" % tn)\n",
        "  print(\"False Positives: %s\" % fp)\n",
        "  print(\"False Negatives: %s\" % fn)\n",
        "  print(\"True Positives: %s\" % tp)\n",
        "\n",
        "  accuracy_clean = (tp + tn) / (tp + tn + fp + fn)\n",
        "  print(f'Accuracy: {round(accuracy_clean,4)}')\n",
        "\n",
        "  misclass_clean = (fp + fn) / (tp + tn + fp + fn)\n",
        "  print(f'Misclassification Rate: {round(misclass_clean,4)}')\n",
        "\n",
        "  spec_clean = tn / (tn + fp) #how many of the 'spam' was correctly classified\n",
        "  print(f'Specificity: {round(spec_clean,4)}')\n",
        "\n",
        "  sens_clean = tp / (tp + fn) #how many of the disasters was correctly identified\n",
        "  print(f'Sensitivity: {round(sens_clean,4)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-YbNI7LPBmm",
        "colab_type": "code",
        "outputId": "05c11893-0f53-4c10-a7e8-ae848b70514d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "conf_unravel(validation_labels,val_flat_predictions)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True Negatives: 387\n",
            "False Positives: 59\n",
            "False Negatives: 67\n",
            "True Positives: 237\n",
            "Accuracy: 0.832\n",
            "Misclassification Rate: 0.168\n",
            "Specificity: 0.8677\n",
            "Sensitivity: 0.7796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWrrE8NwQ0-9",
        "colab_type": "code",
        "outputId": "d248f8bf-5c7e-4cd4-fd32-639b7c3a9cf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(confusion_matrix(validation_labels,val_flat_predictions),annot=True,fmt='g',cmap=plt.cm.Blues);\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.savefig('confusion_matrix_bert.png')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArIAAAGGCAYAAACHemKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKciKiIiIiEf6CVFytsSAcZIsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw6_Y57uTfFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}